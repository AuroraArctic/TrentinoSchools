na.zero <- function (x) {
x[is.na(x)] <- 0
return(x)
}
tn$Pop_under_20 = as.numeric(tn$Pop_under_20)
res_df%>%
group_by(Column) %>%
summarise("Median Moran" = median(Moran_I_statistic), "Median p-value" =  median(p_value),
"Mean Moran" = round(mean(Moran_I_statistic),4), "Mean p-value" = round(mean(p_value),4)) %>%
DT::datatable()
lmI <- localmoran(tn$Pop_under_20_Pop_tot, dnb24.list,
na.action = na.exclude)
# Libraries
library(tidyverse)
library(spdep)
library(rgdal)
library(sf)
library(sp)
library(rgeos)
library(terra)
library(DT)
# Function that creates a palette from
# yellow to red
colours_palette = colorRampPalette(c("#fedb71","#FCD471","#facd71",
"#f6bf70","#eea26f","#EA946F",
"#e6866e","#e2786e","#e0716e","#dd696d"))
# Read municipality data
tn <- readOGR("../data/aggregated_data_per_municipality", encoding="UTF-8")
# Setting the CRS
tn <- spTransform(tn, CRS("+init=epsg:4326"))
# Function to replace NAs with 0
na.zero <- function (x) {
x[is.na(x)] <- 0
return(x)
}
tn$Pop_under_20 = as.numeric(tn$Pop_under_20)
lmI <- localmoran(tn$Pop_under_20_Pop_tot, dnb24.list,
na.action = na.exclude)
tn$Pop_under_20_Pop_tot
tn$Pop_under_20
# Read municipality data
tn <- readOGR("../data/aggregated_data_per_municipality", encoding="UTF-8")
# Read municipality data
tn <- readOGR("../data/aggregated_data_per_municipality", encoding="UTF-8")
# Setting the CRS
tn <- spTransform(tn, CRS("+init=epsg:4326"))
# Function to replace NAs with 0
na.zero <- function (x) {
x[is.na(x)] <- 0
return(x)
}
tn$Pop_under_20
tn$Pop.under
tn$Pop_under = as.numeric(tn$Pop_under)
tn$Pop.under
tn$Pop.under = as.numeric(tn$Pop.under)
tn$Pop.under
tn$Stud.Pop_s
tn$Pop_stud.P
# Libraries
library(tidyverse)
library(spdep)
library(rgdal)
library(sf)
library(sp)
library(rgeos)
library(terra)
library(DT)
# Function that creates a palette from
# yellow to red
colours_palette = colorRampPalette(c("#fedb71","#FCD471","#facd71",
"#f6bf70","#eea26f","#EA946F",
"#e6866e","#e2786e","#e0716e","#dd696d"))
# Read municipality data
tn <- readOGR("../data/aggregated_data_per_municipality", encoding="UTF-8")
# Setting the CRS
tn <- spTransform(tn, CRS("+init=epsg:4326"))
# Function to replace NAs with 0
na.zero <- function (x) {
x[is.na(x)] <- 0
return(x)
}
tn$Pop.under = as.numeric(tn$Pop.under)
tn$Popolazion = as.numeric(tn$Popolazion)
names(tn@data)[3] = "Scuole"
names(tn@data)[7] = "Media_stud_classe"
names(tn@data)[8] = "Media_stud_scuola"
names(tn@data)[10] = "Pop_under_20"
names(tn@data)[11] = "Pop_under_20_Pop_tot"
names(tn@data)[12] = "Stud_Pop_under_20"
# Replace NAs about municipalities' number of schools with 0s
tn@data$Scuole = na.zero(tn@data$Scuole)
# Plot the municipalities in Trentino
par(mar=c(0,0,0,0))
plot(tn, axes = F, border="grey")
# Import shapefile as SpatialPointsDataFrame
schools <- readOGR("../data/Trentino/schools/schools.shp",verbose = FALSE)
# Setting the CRS
schools <- spTransform(schools, CRS("+init=epsg:4326"))
# Plot schools over Trentino's map
par(mar=c(0,0,0,0))
plot(tn, border = "grey", axes = F)
points(schools@coords, col = alpha("#f27059",0.3), cex = 1, pch = 16)
par(mar=c(0,0,0,0))
plot(tn, border="grey")
points(coordinates(tn),
col="red",
bg = "#EF798A",
pch = 21,
lwd = 1.5)
tn_coords = coordinates(tn)
tn@data$centroid = tn_coords
colorize = c()
for(i in 1:166){
colorize = append(colorize, point.in.polygon(tn$centroid[i,1],
tn$centroid[i,2],
tn@polygons[i][[1]]@Polygons[[1]]@coords[,1],
tn@polygons[i][[1]]@Polygons[[1]]@coords[,2]))
}
par(mar = c(0,0,0,0))
plot(tn, col = ifelse(colorize, "white","lightgrey"), border="grey")
text(tn_coords, labels = ifelse(colorize, "" ,tn@data$Comune), cex=0.6)
par(mar=c(0,0,0,0))
trueCentroids = gCentroid(tn,byid=TRUE)
plot(tn, border="grey")
points(coordinates(tn),pch=1, col="blue")
points(trueCentroids,pch=2, col="red")
# Saving schools coordinates
school_coords = coordinates(schools)
knitr::include_graphics("../viz/knn/knn.gif")
k <- knn2nb(knearneigh(school_coords, k = 1, longlat=T))
par(mar = c(0,0,0,0))
plot(tn, border = "grey80", axis = tn, lwd=0.5)
plot(k, school_coords, lwd=5,
col=alpha("#F27059",alpha=0.5),
cex = .8, add=TRUE, points=FALSE)
text(tn_coords, labels = ifelse(tn@data$Comune %in% c("Vermiglio","Rabbi",
"MalÃ©","Luserna",
"Lavarone","Predaia"),
tn@data$Comune, ""), cex=0.6)
knitr::include_graphics("../viz/knn/20_parks.png")
knn1 = knn2nb(knearneigh(tn_coords, k = 1, longlat=T))
knn2 = knn2nb(knearneigh(tn_coords, k = 2, longlat=T))
knn3 = knn2nb(knearneigh(tn_coords, k = 3, longlat=T))
knn4 = knn2nb(knearneigh(tn_coords, k = 4, longlat=T))
knn5 = knn2nb(knearneigh(tn_coords, k = 5, longlat=T))
par(mar=c(0,0,0,0))
plot(tn, border = "grey80", axis = tn, lwd=0.5)
plot(knn5, tn_coords, lwd=.6, col=alpha("#F27059",alpha=0.5),
cex = .3, add=TRUE, points=FALSE)
# Critical cut-off on schools
knn1<- knn2nb(knearneigh(school_coords, k=1, longlat=T))
all.linked <- max(unlist(nbdists(knn1, school_coords, longlat=T)))
all.linked
distances = unlist(nbdists(knn1,school_coords,longlat=T))
ggplot()+
geom_histogram(aes(x=distances), fill='#F27059', bins=50)+
labs(title = "Distribution of distances between schools")+
theme_minimal()
# Critical cut-off on municipalities
knn1<- knn2nb(knearneigh(tn_coords,k=1,longlat=T))
all.linked <- max(unlist(nbdists(knn1,tn_coords,longlat=T)))
all.linked
distances = unlist(nbdists(knn1,tn_coords,longlat=T))
ggplot()+
geom_histogram(aes(x=distances), fill='#F27059', bins=50)+
labs(title="Distribution of distances between municipalities' centroids")+
theme_minimal()
dnb10 <- dnearneigh(school_coords, 0, 10, longlat=TRUE); dnb10
dnb15 <- dnearneigh(school_coords, 0, 15, longlat=TRUE); dnb15
dnb20 <- dnearneigh(school_coords, 0, 20, longlat=TRUE); dnb20
dnb25 <- dnearneigh(school_coords, 0, 25, longlat=TRUE); dnb25
dnb30 <- dnearneigh(school_coords, 0, 30, longlat=TRUE); dnb30
plot_neighbour = function(model, coords, title){
par(mar=c(0,0,1,0))
plot(tn, border="grey",xlab="",ylab="",xlim=NULL)
title(main=title, cex.main=0.8)
plot(model, coords, add=TRUE, col="#F27059", pch=16, lwd = 1, points=FALSE)
}
par(mfrow = c(3,2))
plot_neighbour(dnb10, school_coords, "d nearest neighbours, d = 10")
plot_neighbour(dnb15, school_coords, "d nearest neighbours, d = 15")
plot_neighbour(dnb20, school_coords, "d nearest neighbours, d = 20")
plot_neighbour(dnb25, school_coords, "d nearest neighbours, d = 25")
plot_neighbour(dnb30, school_coords, "d nearest neighbours, d = 30")
dnb12 <- dnearneigh(tn_coords, 0, 12, longlat=TRUE); dnb12
dnb16 <- dnearneigh(tn_coords, 0, 16, longlat=TRUE); dnb16
dnb20 <- dnearneigh(tn_coords, 0, 20, longlat=TRUE); dnb20
dnb24 <- dnearneigh(tn_coords, 0, 24, longlat=TRUE); dnb24
dnb30 <- dnearneigh(tn_coords, 0, 30, longlat=TRUE); dnb30
par(mfrow = c(3,2))
plot_neighbour(dnb12, tn_coords, "d nearest neighbours, d = 12")
plot_neighbour(dnb16, tn_coords, "d nearest neighbours, d = 16")
plot_neighbour(dnb20, tn_coords, "d nearest neighbours, d = 20")
plot_neighbour(dnb24, tn_coords, "d nearest neighbours, d = 24")
plot_neighbour(dnb30, tn_coords, "d nearest neighbours, d = 30")
# Quantiles of areas of municipalities within the Province of Trento
tn@data$area = round(area(tn)/ 1000000,3)
area = tn@data %>%
arrange(desc(area)) %>%
select(Comune, area)
quantile(area$area)
# Find max distance within the province centroids
library(geosphere)
diff = c()
for(i in 1:166 ){
for (j in 1:166){
diff = append(diff, distm(tn_coords[i,],tn_coords[j,], fun = distHaversine))
}
}
# Maximum distance between centroids within the province of Trento
max(diff)/1000
par(mar=c(0,0,0,0))
contnb_q <- poly2nb(tn, queen=T)
plot(tn, border="grey")
plot(contnb_q, tn_coords, add=TRUE, col="#EF798A")
points(coordinates(tn),
col="red",
bg = "#EF798A",
pch = 21,
lwd = 1.5)
area%>%
DT::datatable()
par(mar = c(0,0,0,0))
plot(tn, col = ifelse(tn@data$Comune %in% area[1:10,'Comune'], "lightgrey" , "white"), border="grey")
text(tn_coords, labels = ifelse(tn@data$Comune %in% area[1:10,'Comune'], tn@data$Comune , ""), cex=0.6)
# K-nearest neighbour
knn1.list = nb2listw(knn1)
knn2.list = nb2listw(knn2)
knn3.list = nb2listw(knn3)
knn4.list = nb2listw(knn4)
knn5.list = nb2listw(knn5)
# Critical cut-off
dnb12.list = nb2listw(dnb12,style="W")
dnb16.list = nb2listw(dnb16,style="W")
dnb20.list = nb2listw(dnb30,style="W")
dnb24.list = nb2listw(dnb24,style="W")
dnb30.list = nb2listw(dnb30,style="W")
# Contiguity based approach
contnb_q.list = nb2listw(contnb_q)
# List with weights lists and their names
weights = list(
list(knn1.list, "K-nearest neighbour (k=1)"),
list(knn2.list, "K-nearest neighbour (k=2)"),
list(knn3.list, "K-nearest neighbour (k=3)"),
list(knn4.list, "K-nearest neighbour (k=4)"),
list(knn5.list, "K-nearest neighbour (k=5)"),
list(dnb12.list, "Critical cut-off neighbourhood (d=12)"),
list(dnb16.list, "Critical cut-off neighbourhood (d=16)"),
list(dnb20.list, "Critical cut-off neighbourhood (d=20)"),
list(dnb24.list, "Critical cut-off neighbourhood (d=24)"),
list(dnb30.list, "Critical cut-off neighbourhood (d=30)"),
list(contnb_q.list, "Contiguity-based neighbourhoord")
)
cols = list(tn$Scuole,tn$Studenti, tn$Classi, tn$Media_stud_scuola,
tn$Pop_under_20_Pop_tot, tn$Stud_Pop_under_20, tn$Media_stud_classe)
titles = c("Schools","Students","Classes","Mean of students per school",
"Population under 20 over Total Population",
"Students over Population under 20", "Mean students per class")
colours <- colours_palette(10)
na.ignore = function(x){
x[is.na(x)] <- -1
return(x)
}
par(mfrow=c(4,2),mar = c(0,0,1.7,0))
for(i in 1:7){
c = na.ignore(unlist(cols[i]))
brks <- round(quantile(c, seq(0,1,0.1)), digits=3)
plot(tn, col=ifelse(c==-1,
"#ffffff",
colours[findInterval(c, brks, all.inside=TRUE)]),
main = titles[i], cex.main=2.5)
}
Neighbourhood = c()
Column = c()
Sd = c()
p_value = c()
Moran_I_statistic = c()
Mean = c()
Var = c()
Assumption = c()
# Iterate over columns
for(i in 1:length(cols)){
# Iterate over neighbourhood
for (w in weights) {
c = na.zero(unlist(cols[i]))
# Iterate over assumptions
for (rand in c(T,F)) {
Neighbourhood = append(Neighbourhood, w[[2]])
res = moran.test(c, w[[1]], randomisation = rand)
Column = append(Column, titles[i])
Sd = append(Sd, round(as.numeric(res[[1]]),4))
p_value = append(p_value, round(as.numeric(res[[2]]), 4))
Moran_I_statistic = append(Moran_I_statistic, round(as.numeric(res[[3]][1]),4))
Mean = append(Mean, round(as.numeric(res[[3]][2]),4))
Var = append(Var, round(as.numeric(res[[3]][3]),4))
if(rand) {
Assumption = append(Assumption, "Randomization")
}else{
Assumption = append(Assumption, "Normality")
}
}
Neighbourhood = append(Neighbourhood, w[[2]])
res = moran.mc(c, w[[1]], nsim=999)
Column = append(Column, titles[i])
Sd = append(Sd,round(as.numeric(res[[1]]),4))
p_value = append(p_value, round(res$p.value),4)
Moran_I_statistic = append(Moran_I_statistic, round(res$statistic,4))
Mean = append(Mean, "")
Var = append(Var, "")
Assumption = append(Assumption, res$method)
}
}
# create df with results and show them
res_df = data.frame(Column, Neighbourhood, Moran_I_statistic, p_value,
Sd, Mean, Var, Assumption)
res_df %>%
arrange(desc(abs(Moran_I_statistic)), p_value) %>%
DT::datatable()
res_df%>%
group_by(Column) %>%
summarise("Median Moran" = median(Moran_I_statistic), "Median p-value" =  median(p_value),
"Mean Moran" = round(mean(Moran_I_statistic),4), "Mean p-value" = round(mean(p_value),4)) %>%
DT::datatable()
LinearMean <- lm(Media_stud_classe ~ Stud_Pop_under_20+Scuole+Classi+Media_stud_scuola+Pop_under_20_Pop_tot+Studenti, tn, na.action = na.ignore)
summary(LinearMean)
# Searching for a simplified model where every feature has high significance
LinearMean = step(LinearMean)
summary(LinearMean)
par(mar=c(0,0,1,0))
studres <- rstudent(LinearMean)
resdistr <- round(quantile(studres, seq(0,1,0.25)), digits=3)
colours_5 <- colours_palette(5)
plot(tn, col=colours_5[findInterval(studres, resdistr, all.inside=TRUE)],
main = "Residuals quantiles in Trentino",
border="grey20")
ols_res = data.frame(Neighbourhood = c(""),
Moran = c(""),
p_value = c(""))
# Moran test on residuals
for(i in 4:11){
t = lm.morantest(LinearMean,weights[[i]][[1]],resfun=rstudent)
ols_res = rbind(ols_res, c(weights[[i]][[2]],
t$estimate['Observed Moran I'],
t$p.value))
}
ols_res$Moran = as.numeric(ols_res$Moran)
ols_res$p_value = as.numeric(ols_res$p_value)
ols_res %>%
arrange(desc(abs(Moran))) %>%
filter(!is.na(Moran)) %>%
DT::datatable()
LinearPop <- lm(tn$Pop_under_20_Pop_tot ~ Stud_Pop_under_20 + Scuole +
Classi + Media_stud_scuola + Media_stud_classe + Studenti, tn)
summary(LinearPop)
# Searching for a simplified model where every feature has high significance
LinearPop = step(LinearPop)
summary(LinearPop)
ols_res = data.frame(Neighbourhood = c(""),
Moran = c(""),
p_value = c(""))
# Moran test on residuals
for(i in 4:11){
t = lm.morantest(LinearPop,weights[[i]][[1]],resfun=rstudent)
ols_res = rbind(ols_res, c(weights[[i]][[2]],
t$estimate['Observed Moran I'],
t$p.value))
}
ols_res$Moran = as.numeric(ols_res$Moran)
ols_res$p_value = as.numeric(ols_res$p_value)
ols_res %>%
arrange(desc(abs(Moran))) %>%
filter(!is.na(Moran)) %>%
DT::datatable()
par(mar=c(0,0,1,0))
studres <- rstudent(LinearPop)
resdistr <- round(quantile(studres, seq(0,1,0.25)), digits=3)
plot(tn, col=colours_5[findInterval(studres, resdistr, all.inside=TRUE)],
main = "Residuals quantiles in Trentino")
mps = list()
for (w in weights) {
mps = append(mps, list(moran.plot(
na.zero(tn@data$Pop_under_20_Pop_tot),
listw = w[[1]],
labels = tn$Comune,
return_df=T)))
}
par(mfrow = c(4,3))
i = 1
plots = list()
for(mp in mps){
xname <- attr(mp, "xname")
p = ggplot(mp, aes(x=x, y=wx)) + geom_point(shape=1) +
geom_smooth(formula=y ~ x, method="lm", color = "#EF798A", fill="#EF798A") +
geom_hline(yintercept=mean(mp$wx), lty=2) +
geom_vline(xintercept=mean(mp$x), lty=2) + theme_minimal() +
geom_point(data=mp[mp$is_inf,], aes(x=x, y=wx), shape=9) +
geom_text(data=mp[mp$is_inf,], aes(x=x, y=wx, label=labels, vjust=1.5), size=3) +
xlab(xname) + ylab(paste0("Spatially lagged ", xname))+
labs(title=weights[i][[1]][[2]])
plots = append(plots, p)
ggsave(p, filename = paste0("pop_20_tot_",weights[i][[1]][[2]],".png"), path = "../viz/moran_scatterplot/", dpi=300)
i = i+1
}
library(knitr)
myimages<-list.files("../viz/moran_scatterplot", pattern = "pop_20_tot_", full.names = TRUE)
include_graphics(myimages)
# PLOTTING REGIONS OF INFLUENCE ABOUT STUDENTS OVER POPULATION UNDER 20
color_mapping = list("LL" = "#FEDB71",
"LH" = "#F6Bf70",
"HL" = "#E6866E",
"HH" = "#E0716E",
"None" = "white")
define_quadrants = function(obs, listw){
obs = na.ignore(obs)
hotspot <- as.numeric(row.names(as.data.frame(summary(moran.plot(
obs,
listw = listw,
return_df=F)))))
tn$wx <- lag.listw(listw, obs)
quadrant <- rep("None", length(obs))
for(i in 1:length(hotspot))  {
if (obs[hotspot[i]]>mean(obs) & tn$wx[hotspot[i]]> mean(tn$wx))
quadrant[hotspot[i]] <- "HH"
if (obs[hotspot[i]]>mean(obs) & tn$wx[hotspot[i]]< mean(tn$wx))
quadrant[hotspot[i]] <- "HL"
if (obs[hotspot[i]]<mean(obs) & tn$wx[hotspot[i]]<mean(tn$wx))
quadrant[hotspot[i]] <- "LL"
if (obs[hotspot[i]]<mean(obs) & tn$wx[hotspot[i]]>mean(tn$wx))
quadrant[hotspot[i]] <- "LH"
}
return(quadrant)
}
quadrants.knn = define_quadrants(tn$Pop_under_20_Pop_tot, knn5.list)
quadrants.cont = define_quadrants(tn$Pop_under_20_Pop_tot, contnb_q.list)
quadrants.dnb = define_quadrants(tn$Pop_under_20_Pop_tot, dnb20.list)
table(quadrants.knn)
table(quadrants.dnb)
table(quadrants.cont)
par(mfrow=c(3,1))
par(mar=c(0,0,0,0))
quadrants = list(list(quadrants.knn,"KNN"), list(quadrants.dnb,"Cut-off"), list(quadrants.cont,"Contiguity"))
for(l in quadrants){
colourization = unlist(color_mapping[l[[1]]])
par(mar=c(0,0,1,0))
plot(tn, col=colourization, border = "grey", main=paste0("Regions with influence on students over population under 20 (neighbourhood = ",l[[2]],")"))
legend(x=11.38, y=45.95, legend=c("Low-Low", "Low-High", "High-Low", "High-High","None"),
fill=unlist(color_mapping), bty="n", cex=0.8)
text(tn_coords, labels = ifelse(l[[1]]=="None", "" ,tn@data$Comune), cex=0.7)
}
# Municipalities in common between KNN and cut-off
tn$Comune[quadrants.knn != "None" & quadrants.dnb != "None"]
# Novaledo in common in contiguity and knn
tn$Comune[quadrants.cont != "None" & quadrants.knn != "None"]
# Nothing in common between contiguity and cut-off
tn$Comune[quadrants.cont != "None" & quadrants.dnb != "None"]
lmI <- localmoran(tn$Pop_under_20_Pop_tot, dnb24.list,
na.action = na.exclude)
lmI = data.frame(lmI)
rownames(lmI) = tn$Comune
# List of municipalities ordered by Local Moran's I
# and below 0.05 p-value
lmI_sign = lmI%>%
filter(lmI$Pr.z....E.Ii..<0.05) %>%
arrange(desc(abs(Ii)))
DT::datatable(lmI_sign)
# Proportion of significant municipalities in Moran's Scatterplot
# versus those identified through Local Moran's
sum(c(tn$Comune[quadrants.knn != "None" |
quadrants.dnb != "None" |
quadrants.cont != "None"]) %in% rownames(lmI_sign))/dim(lmI_sign)[1]
par(mar=c(0,0,1,0))
brks <- sort(as.numeric(lmI[,1]))
colours <- colorRampPalette(c('#fedb71','#dd696d'))(length(lmI[,1]))
plot(tn, col=colours[findInterval(lmI[,1], brks, all.inside=TRUE)],
border="grey30")
title(main="Local Moran's I values")
text(tn_coords, labels = ifelse(tn@data$Comune %in% rownames(lmI_sign), tn@data$Comune ,""), cex=0.7)
# Mapping the p-value as color
pvalue_colors = c("white","#fedb71", "#F6BF70", "#E6866E","#DD696D")
pval <- as.numeric(lmI[,5])
colpval = ifelse(pval>0.05, pvalue_colors[1],
ifelse(pval>0.01 & pval<=0.05, pvalue_colors[2],
ifelse(pval>0.001 & pval<=0.01,pvalue_colors[3],
ifelse(pval>0.0001,pvalue_colors[4],pvalue_colors[5]))))
tn$colpval[pval>0.05] <- "white"
tn$colpval[pval<=0.05 & pval>0.01] <- gray(0.9)
tn$colpval[pval<=0.01 & pval>0.001] <- gray(0.7)
tn$colpval[pval<=0.001 & pval>0.0001] <- gray(0.4)
tn$colpval[pval<=0.0001] <- "black"
plot(tn, col=colpval)
legend(x=11.5, y=45.9, legend=c("Not significant",
"p-value = 0.05", "p-value = 0.01", "p-value = 0.001",
"p-value = 0.0001"), fill=pvalue_colors, bty="n", cex=1)
title(main="Local Moran's I significance map")
text(tn_coords, labels = ifelse(colpval == "white","", tn@data$Comune), cex=0.7)
library(spatialreg)
# Estimate the SDM model using the Maximum likelihood estimator
SDM <- lagsarlm(Pop_under_20_Pop_tot ~ Stud_Pop_under_20 + Scuole +
Media_stud_scuola + Studenti, tn, listw=dnb16.list,
type="mixed", na.action = na.ignore)
summary(SDM)
# Estimate the LDM model using the OLS estimator
LDM <- lmSLX(Pop_under_20_Pop_tot ~ Stud_Pop_under_20 + Scuole +
Media_stud_scuola + Studenti,tn, listw=dnb16.list, na.action = na.ignore)
summary(LDM)
#For the SD specification:
impSDM <- impacts(LDM, listw=dnb16.list, R=100)
summary(impSDM, zstats=TRUE, short=TRUE)
SDM
SDM
summary(impSDM, zstats=TRUE, short=TRUE)
